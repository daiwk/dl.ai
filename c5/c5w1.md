# c5w1

contents

* [1. Recurrent Neural Networks](c5w1.md#1-recurrent-neural-networks)
  * [1.1 Why sequence models](c5w1.md#11-why-sequence-models)
  * [1.2 Notation](c5w1.md#12-notation)
  * [1.3 Recurrent Neural Network Model](c5w1.md#13-recurrent-neural-network-model)
  * [1.4 Backpropagation through time](c5w1.md#14-backpropagation-through-time)
  * [1.5 Different type of RNNs](c5w1.md#15-different-type-of-rnns)
  * [1.6 Language model and sequence generation](c5w1.md#16-language-model-and-sequence-generation)
  * [1.7 Sampling noval sequences](c5w1.md#17-sampling-noval-sequences)
  * [1.8 Vanishing gradients with RNNs](c5w1.md#18-vanishing-gradients-with-rnns)
  * [1.9 Gated Recurrent Unit\(GRU\)](c5w1.md#19-gated-recurrent-unitgru)
  * [1.10 Long Short Term Memory\(LSTM\)](c5w1.md#110-long-short-term-memorylstm)
  * [1.11 Bidirectional RNN](c5w1.md#111-bidirectional-rnn)
  * [1.12 Deep RNNs](c5w1.md#112-deep-rnns)

## 1. Recurrent Neural Networks

### 1.1 Why sequence models

### 1.2 Notation

### 1.3 Recurrent Neural Network Model

### 1.4 Backpropagation through time

### 1.5 Different type of RNNs

### 1.6 Language model and sequence generation

### 1.7 Sampling noval sequences

### 1.8 Vanishing gradients with RNNs

### 1.9 Gated Recurrent Unit\(GRU\)

### 1.10 Long Short Term Memory\(LSTM\)

### 1.11 Bidirectional RNN

### 1.12 Deep RNNs

